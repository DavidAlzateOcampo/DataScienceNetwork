{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tree_Test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidAlzateOcampo/DataScienceNetwork/blob/master/Tree_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsJ_G8LY2zXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load packages\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier #The algorithm\n",
        "from sklearn.model_selection import train_test_split #Train and test split function\n",
        "from sklearn import metrics #To calculate model accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0tyynDd2-MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Loading the data\n",
        "raw_dataset = pd.read_csv(\"/content/sample_data/bank-full.csv\", header = 0, delimiter = ';')\n",
        "raw_dataset.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp7DZoyY3Bph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataset.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-YqRsm5-_UE",
        "colab_type": "text"
      },
      "source": [
        "+ (1) These 3 are all numerical. Modify the code so that you include categorical features of ‘marital’ and ‘education’ into the training and test datasets.\n",
        "\n",
        "**David :** In the next chunk of code it was added the 2 new features marital and education.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajApRb5o3F2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets do some feature selection \n",
        "feature_names = ['age', 'balance', 'duration','marital','education']\n",
        "X = raw_dataset[feature_names] #Selected features\n",
        "y = raw_dataset.y #Target feature (i.e., class label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO57_nw03RNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#The full dataset is randomly divided into the \"train\" and \"test\" sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1) #80% training and 20% test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZWJZwu__rJu",
        "colab_type": "text"
      },
      "source": [
        "+ (2) Try to train a decision tree classifier. What error do you get? What is the reason behind that?\n",
        "\n",
        "**David :** The reason why the training fails is the way, fit method for DecisionTreeClassifier was implemented internally. In the documentation link in [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit) it mentions that input X parameter must be an array-like or sparse matrix. Moreover, it mentiones that internally, it will be converted to dtype=np.float32.\n",
        "\n",
        "Based on the documentation, the method does not expect a character feature, and that's the reason of the error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7maSlh7F3TyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 3)\n",
        "#Train a Decision Tree model\n",
        "clf = clf.fit(X_train,y_train)\n",
        "#Use the model to predict the response for our test dataset\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k3gp0J2CFBF",
        "colab_type": "text"
      },
      "source": [
        "+ (3) Find a way to pass the categorical variables to the Decision Tree algorithm in Scikit-Learn.\n",
        "\n",
        "**David :** it was implemented the next code which verifies the type of the feature and for dtypes object, it appends the feature name as a categorical variable. Then, it obtains the numerical features. After that, it converts the categorical features to dummies columns, it means it create one column for each category of the features, and then it fills the samples with 1 or 0 in the new features. \n",
        "\n",
        "The reason why the training fails is the way, fit method for DecisionTreeClassifier was implemented internally. In the documentation link in [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit) it mentions that input X parameter must be an array-like or sparse matrix. Moreover, it mentiones that internally, it will be converted to dtype=np.float32 .\n",
        "\n",
        "Based on the documentation, the method does not expect a character feature, and that's the reason of the error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0FTQY3w655v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Empty list to store columns with categorical data\n",
        "categorical = []\n",
        "for col, value in X.iteritems():\n",
        "    if value.dtype == 'object':\n",
        "        categorical.append(col)\n",
        "        \n",
        "# Store the numerical columns in a list numerical\n",
        "numerical = X.columns.difference(categorical)\n",
        "\n",
        "# Store the categorical data in a dataframe called attrition_cat\n",
        "X_cat = X[categorical]\n",
        "\n",
        "X_cat = pd.get_dummies(X_cat)\n",
        "\n",
        "X_num = X[numerical]\n",
        "# Concat the two dataframes together columnwise\n",
        "X_final = []\n",
        "X_final = pd.concat([X_num, X_cat], axis=1)\n",
        "X_final.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-W75MI9738A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The full dataset is randomly divided into the \"train\" and \"test\" sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size = 0.2, random_state = 1) #80% training and 20% test\n",
        "\n",
        "#Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 3)\n",
        "#Train a Decision Tree model\n",
        "clf = clf.fit(X_train,y_train)\n",
        "#Use the model to predict the response for our test dataset\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy2sJq0iFGKg",
        "colab_type": "text"
      },
      "source": [
        " + (4) Did inclusion of new features improve the predictive accuracy of your model?\n",
        " \n",
        "**David :** The accuracy remained the same. The reason is because the max_depth is 3 and it means new 2 features (marital, education) are not as important as the initial 3 features (age, balance, and duration). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTdk3AWp3WTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noIc4I97IWu0",
        "colab_type": "text"
      },
      "source": [
        "**David:** I trained the model but changing the max_depth to 4. It slightly improved the accuracy by 0.03%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR18MUyJH84i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 4)\n",
        "#Train a Decision Tree model\n",
        "clf = clf.fit(X_train,y_train)\n",
        "#Use the model to predict the response for our test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUs3GNbE3YUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########## Visualizing the tree ##########\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf7Tob9J8eV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(feature_names)\n",
        "feature_names = list(X_final.columns)\n",
        "print(feature_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVCA_kz73eUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = feature_names, class_names=['no','yes'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('bank_decision_tree.png')\n",
        "Image(graph.create_png())\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}